{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "\n",
    "from scraper import Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client = MongoClient()\n",
    "db = mongo_client.dearabby\n",
    "\n",
    "archives_coll = db.archives\n",
    "articles_coll = db.articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = Scraper(archives_coll, articles_coll, year_start=1991, year_end=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape(archives_coll, articles_coll, year_start=1991, year_end=2021):\n",
    "#     base_url = 'https://www.uexpress.com/dearabby'\n",
    "#     archive_status = []\n",
    "#     article_status = []\n",
    "    \n",
    "#     for i in range(year_start, year_end):\n",
    "#         print('year:', i)\n",
    "#         print()\n",
    "#         url = base_url + '/archives/' + str(i)\n",
    "        \n",
    "#         status_code, archive = scrape_insert(archives_coll, url)\n",
    "        \n",
    "#         archive_status.append({url: status_code})\n",
    "        \n",
    "#         if status_code == 200:\n",
    "#             status_codes = scrape_articles(articles_coll, archive)\n",
    "            \n",
    "#             article_status.append({url: status_codes})\n",
    "            \n",
    "#         if (i - year_start) == 5:\n",
    "#             print('sleep 30 in archive')\n",
    "#             print(url)\n",
    "#             print()\n",
    "#             time.sleep(30)\n",
    "            \n",
    "#         if (i - year_start) == 10:\n",
    "#             print('sleep 60 in archive')\n",
    "#             print(url)\n",
    "#             print()\n",
    "#             time.sleep(60)\n",
    "        \n",
    "        \n",
    "#     return archive_status, article_status\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def scrape_articles(coll, archive):\n",
    "#     soup = BeautifulSoup(archive, 'lxml')\n",
    "#     base_url = 'https://www.uexpress.com'\n",
    "    \n",
    "#     list_of_articles = soup.select('article.media.media-item.list-item--large')\n",
    "    \n",
    "#     status = []\n",
    "    \n",
    "#     for i, article in enumerate(list_of_articles):\n",
    "#         url = base_url + article.select('a.media__link--primary')[0]['href']\n",
    "        \n",
    "#         status_code, article = scrape_insert(coll, url)\n",
    "        \n",
    "#         status.append({'url': url,\n",
    "#                        'status_code': status_code, \n",
    "#                        'article': article})\n",
    "        \n",
    "#         if i % 10 == 9:\n",
    "#             print('sleep 30 in article')\n",
    "#             print(url)\n",
    "#             print()\n",
    "#             time.sleep(30)\n",
    "        \n",
    "#     return status\n",
    "        \n",
    "            \n",
    "\n",
    "# def scrape_insert(coll, url):\n",
    "#     response = requests.get(url)\n",
    "    \n",
    "#     print('sleep 2 seconds')\n",
    "#     print(url)\n",
    "#     print()\n",
    "#     time.sleep(2)\n",
    "    \n",
    "#     coll.insert_one({'url': url,\n",
    "#                      'status_code': response.status_code,\n",
    "#                      'html': response.content})\n",
    "\n",
    "#     return response.status_code, response.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scrape(archives_coll, articles_coll, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
